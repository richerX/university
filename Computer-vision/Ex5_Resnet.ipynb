{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvMm-X5Ebk8z"
      },
      "source": [
        "#Show base model\n",
        "\n",
        "Load resnet model form pytorch model zoo"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sH_7IbmspVT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuvoBvYRrV0-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66962ce9-db84-40a4-a3b2-df4aa0e18e1e"
      },
      "source": [
        "from torchvision.models import resnet18\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "resnet_original = resnet18()\n",
        "print(resnet_original)\n",
        "\n",
        "\n",
        "# Helper method to run Tensorboard in Colab\n",
        "def reinit_tensorboard(clear_log = True):\n",
        "  # Directory for log files\n",
        "  logs_base_dir = \"runs\"\n",
        "  if clear_log:\n",
        "    # Clear logs\n",
        "    shutil.rmtree(logs_base_dir, ignore_errors = True)\n",
        "    os.makedirs(logs_base_dir, exist_ok=True)\n",
        "  # Colab magic\n",
        "  %load_ext tensorboard\n",
        "  %tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USjPLWePVnhe"
      },
      "source": [
        "# Show model structure\n",
        "Do the same with your model when you create it.\n",
        "Pay attention to spatial dimension of data in intermediate layers\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEff69xdk3J1"
      },
      "source": [
        "# Display model structure\n",
        "# Do it for your model when \n",
        "\n",
        "import torch\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "reinit_tensorboard()\n",
        "writer = SummaryWriter(comment = \"resnet\")\n",
        "\n",
        "dummy_input = torch.randn([1,3,224,224])\n",
        "writer.add_graph(resnet_original, dummy_input)\n",
        "writer.flush()\n",
        "writer.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6Jy-WhZZ9hf"
      },
      "source": [
        "# Load the dataset\n",
        "\n",
        "Load and preprocess the data. \n",
        "You can change size of datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XF4CtDcInYhP"
      },
      "source": [
        "from torchvision import models, datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import pickle\n",
        "\n",
        "# https://github.com/facebookarchive/fb.resnet.torch/issues/180\n",
        "cifar10_mean = (0.491, 0.482, 0.447)\n",
        "cifar10_std = (0.247, 0.244, 0.262)\n",
        "\n",
        "\n",
        "# Data preprocessing\n",
        "transform=transforms.Compose([\n",
        "                              transforms.ToTensor(), # PIL Image to Pytorch tensor\n",
        "                              transforms.Normalize(cifar10_mean, cifar10_std) # https://pytorch.org/docs/stable/torchvision/transforms.html?highlight=transforms%20normalize#torchvision.transforms.Normalize\n",
        "                              ])\n",
        "\n",
        "dataset = datasets.CIFAR10(\"content\", train=True, transform = transform ,  download=True)\n",
        "\n",
        "# Split dataset into train and val\n",
        "train_ds, val_ds, _= random_split(dataset, [10000, 1000 ,39000])\n",
        "\n",
        "with open(\"content/cifar-10-batches-py/batches.meta\",'rb') as infile:\n",
        "  cifar_meta = pickle.load(infile)\n",
        "labels = cifar_meta['label_names']\n",
        "\n",
        "\n",
        "# Validation function. Don't change this code\n",
        "\n",
        "import torch.optim as optim\n",
        "def validate(model,testloader,device):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "  \n",
        "  return correct / total  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8ri0SWkXGo7"
      },
      "source": [
        "# Code for training\n",
        "\n",
        "Feel free to change hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDhyfuW7nktR"
      },
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "def train(model):\n",
        "  writer = SummaryWriter(comment = \"resnet\")\n",
        "  # Run model on cuda\n",
        "  device = torch.device(\"cuda\")\n",
        "  \n",
        "  model.train()\n",
        "  model.to(device)\n",
        "\n",
        "  train_loader = DataLoader(train_ds, batch_size = 128, shuffle = True)\n",
        "  val_loader = DataLoader(val_ds, batch_size = 128, shuffle = False)\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "  best_accuracy = 0\n",
        "\n",
        "  for epoch in range(30):\n",
        "    for img_batch, labels_batch in train_loader:\n",
        "      optimizer.zero_grad()\n",
        "      output = model(img_batch.to(device))\n",
        "      loss = criterion(output, labels_batch.to(device))\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      images = img_batch.cpu()\n",
        "      label_nums = output.cpu()\n",
        "    accuracy = validate(model,val_loader,device)\n",
        "    if best_accuracy < accuracy:\n",
        "      best_accuracy = accuracy\n",
        "    writer.add_scalar('Accuracy',accuracy,epoch)\n",
        "    writer.add_scalar('Loss/train',loss.cpu().item(),epoch)\n",
        "    print(\"Epoch {} Loss {:.2f} Accuracy {:.2f}\".format(epoch,loss.item(),accuracy))\n",
        "    writer.flush()\n",
        "  writer.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_kACR3toOBC"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVKMChBMXciC"
      },
      "source": [
        "# Main task\n",
        "\n",
        "Create your ouwn resnet - like model with depth of 15 -25 layers\n",
        "\n",
        "Look at original paper before coding : https://arxiv.org/pdf/1512.03385.pdf\n",
        "Don't directly use code from here: https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py\n",
        "\n",
        "Train and test it on CIFAR10, compare results with original model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5_BAl0iq3-t"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "'''\n",
        "PDF файл из условия не открывается, нет доступа к сайту (видимо, сайт не работает)\n",
        "'''\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, downsample):\n",
        "        super().__init__()\n",
        "        self.shortcut = nn.Sequential()\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
        "        if downsample:\n",
        "            self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
        "            self.shortcut = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=2), nn.BatchNorm2d(out_channels))\n",
        "\n",
        "    def forward(self, input):\n",
        "        shortcut = self.shortcut(input)\n",
        "        input = nn.ReLU()(self.bn1(self.conv1(input)))\n",
        "        input = nn.ReLU()(self.bn2(self.conv2(input)))\n",
        "        input = input + shortcut\n",
        "        return nn.ReLU()(input)\n",
        "\n",
        "class CustomResnet(nn.Module):\n",
        "    def __init__(self, input):\n",
        "        super().__init__()\n",
        "        self.layer0 = nn.Sequential(\n",
        "            nn.Conv2d(input, 64, kernel_size=7, stride=2, padding=3),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.layer1 = nn.Sequential(Block(64, 64, downsample=False), Block(64, 64, downsample=False))\n",
        "        self.layer2 = nn.Sequential(Block(64, 128, downsample=True), Block(128, 128, downsample=False))\n",
        "        self.layer3 = nn.Sequential(Block(128, 256, downsample=True), Block(256, 256, downsample=False))\n",
        "        self.layer4 = nn.Sequential(Block(256, 512, downsample=True), Block(512, 512, downsample=False))\n",
        "\n",
        "    def forward(self, input):\n",
        "        input = self.layer0(input)\n",
        "        input = self.layer1(input)\n",
        "        input = self.layer2(input)\n",
        "        input = self.layer3(input)\n",
        "        input = self.layer4(input)\n",
        "        input = input.reshape(input.size(0), -1)\n",
        "        input = self.fc(input)\n",
        "        return input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUue0PC9XpE2"
      },
      "source": [
        "#Train your model\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "custom_resnet = CustomResnet(3)"
      ],
      "metadata": {
        "id": "HAWKMSKi8q2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reinit_tensorboard()\n",
        "writer = SummaryWriter(comment = \"My custom resnet\")\n",
        "train_loader = DataLoader(train_ds, batch_size = 128, shuffle = True)\n",
        "for img_batch, labels_batch in train_loader:\n",
        "    writer.add_graph(custom_resnet, img_batch.to(torch.device(\"cpu\")))\n",
        "    break\n",
        "writer.flush()\n",
        "writer.close()"
      ],
      "metadata": {
        "id": "drjj03cZ8jE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNmrQKBYynVQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c6a4266-2edc-4467-bdf7-91266f618e3e"
      },
      "source": [
        "train(custom_resnet)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 Loss 3.38 Accuracy 0.31\n",
            "Epoch 1 Loss 1.52 Accuracy 0.39\n",
            "Epoch 2 Loss 1.48 Accuracy 0.42\n",
            "Epoch 3 Loss 2.19 Accuracy 0.43\n",
            "Epoch 4 Loss 1.62 Accuracy 0.48\n",
            "Epoch 5 Loss 1.78 Accuracy 0.50\n",
            "Epoch 6 Loss 1.40 Accuracy 0.54\n",
            "Epoch 7 Loss 1.31 Accuracy 0.55\n",
            "Epoch 8 Loss 1.20 Accuracy 0.56\n",
            "Epoch 9 Loss 1.31 Accuracy 0.58\n",
            "Epoch 10 Loss 1.77 Accuracy 0.60\n",
            "Epoch 11 Loss 1.34 Accuracy 0.60\n",
            "Epoch 12 Loss 1.07 Accuracy 0.61\n",
            "Epoch 13 Loss 1.00 Accuracy 0.62\n",
            "Epoch 14 Loss 0.80 Accuracy 0.65\n",
            "Epoch 15 Loss 1.52 Accuracy 0.62\n",
            "Epoch 16 Loss 0.53 Accuracy 0.61\n",
            "Epoch 17 Loss 0.89 Accuracy 0.62\n",
            "Epoch 18 Loss 0.86 Accuracy 0.60\n",
            "Epoch 19 Loss 0.55 Accuracy 0.62\n",
            "Epoch 20 Loss 0.53 Accuracy 0.61\n",
            "Epoch 21 Loss 1.24 Accuracy 0.62\n",
            "Epoch 22 Loss 0.53 Accuracy 0.63\n",
            "Epoch 23 Loss 0.41 Accuracy 0.59\n",
            "Epoch 24 Loss 0.70 Accuracy 0.64\n",
            "Epoch 25 Loss 0.11 Accuracy 0.63\n",
            "Epoch 26 Loss 0.97 Accuracy 0.62\n",
            "Epoch 27 Loss 0.44 Accuracy 0.62\n",
            "Epoch 28 Loss 0.40 Accuracy 0.62\n",
            "Epoch 29 Loss 0.56 Accuracy 0.63\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Sr2-cZyX4Dg"
      },
      "source": [
        "#Train resnet18 from torchvision.models \n",
        "\n",
        "  Train from scratch Resnet18 on CIFAR-10\n",
        "  Compare results with yours and with results from original paper:\n",
        "\n",
        "\n",
        " https://arxiv.org/pdf/1512.03385.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX78L7iuXymd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24d712c7-4116-4487-a103-1be5dfd9df6d"
      },
      "source": [
        "train(resnet_original)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 Loss 2.04 Accuracy 0.22\n",
            "Epoch 1 Loss 1.74 Accuracy 0.35\n",
            "Epoch 2 Loss 1.69 Accuracy 0.39\n",
            "Epoch 3 Loss 1.48 Accuracy 0.44\n",
            "Epoch 4 Loss 1.53 Accuracy 0.46\n",
            "Epoch 5 Loss 1.93 Accuracy 0.52\n",
            "Epoch 6 Loss 1.11 Accuracy 0.55\n",
            "Epoch 7 Loss 1.21 Accuracy 0.54\n",
            "Epoch 8 Loss 1.08 Accuracy 0.56\n",
            "Epoch 9 Loss 1.43 Accuracy 0.58\n",
            "Epoch 10 Loss 0.74 Accuracy 0.59\n",
            "Epoch 11 Loss 1.07 Accuracy 0.62\n",
            "Epoch 12 Loss 0.44 Accuracy 0.56\n",
            "Epoch 13 Loss 0.58 Accuracy 0.62\n",
            "Epoch 14 Loss 1.23 Accuracy 0.62\n",
            "Epoch 15 Loss 1.47 Accuracy 0.61\n",
            "Epoch 16 Loss 0.49 Accuracy 0.62\n",
            "Epoch 17 Loss 0.58 Accuracy 0.64\n",
            "Epoch 18 Loss 1.11 Accuracy 0.60\n",
            "Epoch 19 Loss 0.33 Accuracy 0.61\n",
            "Epoch 20 Loss 0.86 Accuracy 0.61\n",
            "Epoch 21 Loss 0.66 Accuracy 0.58\n",
            "Epoch 22 Loss 0.26 Accuracy 0.62\n",
            "Epoch 23 Loss 0.11 Accuracy 0.62\n",
            "Epoch 24 Loss 2.56 Accuracy 0.62\n",
            "Epoch 25 Loss 0.96 Accuracy 0.61\n",
            "Epoch 26 Loss 0.72 Accuracy 0.61\n",
            "Epoch 27 Loss 0.46 Accuracy 0.62\n",
            "Epoch 28 Loss 0.71 Accuracy 0.61\n",
            "Epoch 29 Loss 0.69 Accuracy 0.62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwAkO1InYLDc"
      },
      "source": [
        "#Place for conclusion:\n",
        "\n",
        "Для resnet original наилучшее accuracy оказалось 0.64 (epoch = 17), при этом accuracy после 30 epoch стал равен 0.62\n",
        "\n",
        "Для моей resnet наилучшее accuracy оказалось 0.65 (epoch = 14), при этом accuracy после 30 epoch стало 0.63\n",
        "\n",
        "В целом, результаты очень близки, но у моей модели чуть-чуть лучше"
      ]
    }
  ]
}