{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xl24yMNM_I5O"
      },
      "source": [
        "#Обучение классификатора на реальном датасете.\n",
        "\n",
        "##Пояснение:\n",
        "Требуется обучить классификатор определяющий тип велосипеда на небольшом датасете фотографий велосипедов из открытых источников. Допускается использовать пред-обученные модели из torchvision.models\n",
        "По результатам работы составьте отчет.\n",
        "\n",
        "##Задачи:\n",
        "\n",
        "* Загрузите Датасет по ссылке: http://fmb.images.gan4x4.ru/hse/bt_dataset3.zip Используйте встроенные классы из пакета torchvision.datasets либо создайте свой являющийся наследником базового класса Dataset из этого пакета.\n",
        "* Проведите аугментацию данных как минимум 3-мя различными способами. Хотя бы одни из них должен быть реализован самостоятельно.\n",
        "* Используйте технологию Transfer learning: \n",
        "** измените выходной слой выбранной вами предобученной модели.\n",
        "** Заморозьте часть весов.\n",
        "* Обучите модель с использование GPU. Учитывайте особенности данных при выборе и настройке Loss-функции\n",
        "*Оцените результаты.\n",
        "* Напишите отчет.\n",
        "\n",
        "\n",
        "\n",
        "*Сохраняйте веса модели на GoogleDrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwpBOkfFNBvk"
      },
      "source": [
        "! wget http://fmb.images.gan4x4.ru/hse/bt_dataset3.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qujAbDgbf9PV"
      },
      "source": [
        "! unzip bt_dataset3.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.backends.cudnn as cudnn\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import torch.utils.data as data\n",
        "\n",
        "cudnn.benchmark = True\n",
        "plt.ion()   # interactive mode"
      ],
      "metadata": {
        "id": "RgyeuY1H8vrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html#training-the-model\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "data_dir = 'bike/bike_type'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=2) for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "xz3CzeNI2ppv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            \n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'Training complete in {time_elapsed}')\n",
        "    print(f'Best val accuracy: {best_acc}')\n",
        "    \n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "metadata": {
        "id": "MbbGb2oA8SIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = models.resnet18(pretrained=True)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(num_ftrs, len(class_names))\n",
        "model_ft = model_ft.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "47nAKn1e9mXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CG8NH4WB9rES",
        "outputId": "68dfd899-516c-4a1e-d0e3-adaa7a2defee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/24\n",
            "train Loss: 1.2980 Acc: 0.5035\n",
            "val Loss: 0.8961 Acc: 0.7050\n",
            "\n",
            "Epoch 1/24\n",
            "train Loss: 1.1693 Acc: 0.5528\n",
            "val Loss: 0.6249 Acc: 0.7983\n",
            "\n",
            "Epoch 2/24\n",
            "train Loss: 1.0909 Acc: 0.5969\n",
            "val Loss: 0.5865 Acc: 0.8026\n",
            "\n",
            "Epoch 3/24\n",
            "train Loss: 0.9856 Acc: 0.6402\n",
            "val Loss: 0.6997 Acc: 0.7549\n",
            "\n",
            "Epoch 4/24\n",
            "train Loss: 0.9332 Acc: 0.6480\n",
            "val Loss: 0.6782 Acc: 0.8243\n",
            "\n",
            "Epoch 5/24\n",
            "train Loss: 0.9078 Acc: 0.6624\n",
            "val Loss: 0.7683 Acc: 0.7592\n",
            "\n",
            "Epoch 6/24\n",
            "train Loss: 0.9020 Acc: 0.6699\n",
            "val Loss: 0.6512 Acc: 0.7983\n",
            "\n",
            "Epoch 7/24\n",
            "train Loss: 0.6603 Acc: 0.7498\n",
            "val Loss: 0.5985 Acc: 0.8265\n",
            "\n",
            "Epoch 8/24\n",
            "train Loss: 0.6038 Acc: 0.7725\n",
            "val Loss: 0.5558 Acc: 0.8286\n",
            "\n",
            "Epoch 9/24\n",
            "train Loss: 0.6037 Acc: 0.7659\n",
            "val Loss: 0.5729 Acc: 0.8460\n",
            "\n",
            "Epoch 10/24\n",
            "train Loss: 0.5501 Acc: 0.7921\n",
            "val Loss: 0.6004 Acc: 0.8482\n",
            "\n",
            "Epoch 11/24\n",
            "train Loss: 0.5888 Acc: 0.7860\n",
            "val Loss: 0.5543 Acc: 0.8373\n",
            "\n",
            "Epoch 12/24\n",
            "train Loss: 0.5457 Acc: 0.8000\n",
            "val Loss: 0.5446 Acc: 0.8525\n",
            "\n",
            "Epoch 13/24\n",
            "train Loss: 0.5510 Acc: 0.7961\n",
            "val Loss: 0.5695 Acc: 0.8482\n",
            "\n",
            "Epoch 14/24\n",
            "train Loss: 0.5218 Acc: 0.8070\n",
            "val Loss: 0.5213 Acc: 0.8416\n",
            "\n",
            "Epoch 15/24\n",
            "train Loss: 0.5275 Acc: 0.8148\n",
            "val Loss: 0.5748 Acc: 0.8395\n",
            "\n",
            "Epoch 16/24\n",
            "train Loss: 0.5291 Acc: 0.8166\n",
            "val Loss: 0.5546 Acc: 0.8503\n",
            "\n",
            "Epoch 17/24\n",
            "train Loss: 0.5243 Acc: 0.7983\n",
            "val Loss: 0.5136 Acc: 0.8525\n",
            "\n",
            "Epoch 18/24\n",
            "train Loss: 0.5108 Acc: 0.8166\n",
            "val Loss: 0.5360 Acc: 0.8590\n",
            "\n",
            "Epoch 19/24\n",
            "train Loss: 0.5376 Acc: 0.8026\n",
            "val Loss: 0.5305 Acc: 0.8438\n",
            "\n",
            "Epoch 20/24\n",
            "train Loss: 0.5349 Acc: 0.7991\n",
            "val Loss: 0.5779 Acc: 0.8373\n",
            "\n",
            "Epoch 21/24\n",
            "train Loss: 0.4949 Acc: 0.8223\n",
            "val Loss: 0.5540 Acc: 0.8438\n",
            "\n",
            "Epoch 22/24\n",
            "train Loss: 0.5280 Acc: 0.7987\n",
            "val Loss: 0.5355 Acc: 0.8503\n",
            "\n",
            "Epoch 23/24\n",
            "train Loss: 0.5091 Acc: 0.8201\n",
            "val Loss: 0.5632 Acc: 0.8395\n",
            "\n",
            "Epoch 24/24\n",
            "train Loss: 0.5072 Acc: 0.8109\n",
            "val Loss: 0.5269 Acc: 0.8460\n",
            "\n",
            "Training complete in 431.5263147354126\n",
            "Best val accuracy: 0.859002169197397\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_conv = torchvision.models.resnet18(pretrained=True)\n",
        "for param in model_conv.parameters():\n",
        "    param.requires_grad = False\n",
        "num_ftrs = model_conv.fc.in_features\n",
        "model_conv.fc = nn.Linear(num_ftrs, len(class_names))\n",
        "model_conv = model_conv.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "uW949z1fD0R6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_conv = train_model(model_conv, criterion, optimizer_conv, exp_lr_scheduler, num_epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uH_4s3DTD81X",
        "outputId": "739ce833-d733-48a7-8824-2bb1338a6520"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/24\n",
            "train Loss: 1.3351 Acc: 0.4607\n",
            "val Loss: 1.0383 Acc: 0.6074\n",
            "\n",
            "Epoch 1/24\n",
            "train Loss: 1.2918 Acc: 0.5031\n",
            "val Loss: 1.2640 Acc: 0.5163\n",
            "\n",
            "Epoch 2/24\n",
            "train Loss: 1.1906 Acc: 0.5166\n",
            "val Loss: 1.0853 Acc: 0.5922\n",
            "\n",
            "Epoch 3/24\n",
            "train Loss: 1.2130 Acc: 0.5127\n",
            "val Loss: 1.0739 Acc: 0.5879\n",
            "\n",
            "Epoch 4/24\n",
            "train Loss: 1.1641 Acc: 0.5201\n",
            "val Loss: 1.0383 Acc: 0.5792\n",
            "\n",
            "Epoch 5/24\n",
            "train Loss: 1.2076 Acc: 0.5223\n",
            "val Loss: 0.8947 Acc: 0.6681\n",
            "\n",
            "Epoch 6/24\n",
            "train Loss: 1.1489 Acc: 0.5511\n",
            "val Loss: 0.9913 Acc: 0.6356\n",
            "\n",
            "Epoch 7/24\n",
            "train Loss: 1.0123 Acc: 0.5825\n",
            "val Loss: 0.9496 Acc: 0.6399\n",
            "\n",
            "Epoch 8/24\n",
            "train Loss: 1.0047 Acc: 0.5917\n",
            "val Loss: 0.8797 Acc: 0.6377\n",
            "\n",
            "Epoch 9/24\n",
            "train Loss: 0.9784 Acc: 0.6013\n",
            "val Loss: 0.9171 Acc: 0.6356\n",
            "\n",
            "Epoch 10/24\n",
            "train Loss: 0.9731 Acc: 0.6109\n",
            "val Loss: 0.9147 Acc: 0.6334\n",
            "\n",
            "Epoch 11/24\n",
            "train Loss: 0.9808 Acc: 0.5965\n",
            "val Loss: 0.9468 Acc: 0.6247\n",
            "\n",
            "Epoch 12/24\n",
            "train Loss: 1.0065 Acc: 0.5751\n",
            "val Loss: 0.8913 Acc: 0.6508\n",
            "\n",
            "Epoch 13/24\n",
            "train Loss: 0.9796 Acc: 0.5869\n",
            "val Loss: 0.9403 Acc: 0.6161\n",
            "\n",
            "Epoch 14/24\n",
            "train Loss: 0.9645 Acc: 0.6000\n",
            "val Loss: 0.8842 Acc: 0.6443\n",
            "\n",
            "Epoch 15/24\n",
            "train Loss: 0.9644 Acc: 0.5965\n",
            "val Loss: 0.8668 Acc: 0.6811\n",
            "\n",
            "Epoch 16/24\n",
            "train Loss: 0.9561 Acc: 0.6009\n",
            "val Loss: 0.9192 Acc: 0.6161\n",
            "\n",
            "Epoch 17/24\n",
            "train Loss: 0.9515 Acc: 0.5991\n",
            "val Loss: 0.8756 Acc: 0.6811\n",
            "\n",
            "Epoch 18/24\n",
            "train Loss: 0.9343 Acc: 0.6153\n",
            "val Loss: 0.8986 Acc: 0.6486\n",
            "\n",
            "Epoch 19/24\n",
            "train Loss: 0.9543 Acc: 0.6017\n",
            "val Loss: 0.9092 Acc: 0.6421\n",
            "\n",
            "Epoch 20/24\n",
            "train Loss: 0.9425 Acc: 0.6079\n",
            "val Loss: 0.8885 Acc: 0.6551\n",
            "\n",
            "Epoch 21/24\n",
            "train Loss: 0.9497 Acc: 0.6105\n",
            "val Loss: 0.8879 Acc: 0.6312\n",
            "\n",
            "Epoch 22/24\n",
            "train Loss: 0.9492 Acc: 0.6074\n",
            "val Loss: 0.9106 Acc: 0.6399\n",
            "\n",
            "Epoch 23/24\n",
            "train Loss: 0.9406 Acc: 0.6004\n",
            "val Loss: 0.8960 Acc: 0.6443\n",
            "\n",
            "Epoch 24/24\n",
            "train Loss: 0.9544 Acc: 0.5952\n",
            "val Loss: 0.8868 Acc: 0.6529\n",
            "\n",
            "Training complete in 330.00702452659607\n",
            "Best val accuracy: 0.6811279826464208\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "    \n",
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title(f'predicted: {class_names[preds[j]]}')\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)\n",
        "\n",
        "visualize_model(model_conv)\n",
        "plt.ioff()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RMKLtTS7FUe7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cZKaWm1NBDd"
      },
      "source": [
        "#Отчет\n",
        "Первая модель - Best val accuracy: 0.859002169197397\n",
        "\n",
        "Вторая модель - Best val accuracy: 0.6811279826464208\n",
        "\n",
        "Вывод: при переносе весов с помощью Transfer learning - accuracy сильно падате, но тем не менее 0.68 не плохой результат"
      ]
    }
  ]
}